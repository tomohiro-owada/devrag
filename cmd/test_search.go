package main

import (
	"fmt"
	"math/rand"
	"os"
	"time"

	"github.com/towada/markdown-vector-mcp/internal/vectordb"
)

func main() {
	fmt.Fprintf(os.Stderr, "[INFO] Testing vector search functionality...\n")

	// Create temporary database
	dbPath := "/tmp/test_vector_search.db"
	os.Remove(dbPath) // Clean up from previous runs

	// Initialize database
	db, err := vectordb.Init(dbPath)
	if err != nil {
		fmt.Fprintf(os.Stderr, "[FATAL] Failed to initialize database: %v\n", err)
		os.Exit(1)
	}
	defer db.Close()
	defer os.Remove(dbPath) // Clean up

	fmt.Fprintf(os.Stderr, "[INFO] Database initialized successfully\n")

	// Insert test documents with embeddings
	testCases := []struct {
		filename string
		chunks   []string
	}{
		{
			filename: "doc1.md",
			chunks: []string{
				"Introduction to machine learning and artificial intelligence.",
				"Deep learning is a subset of machine learning.",
				"Neural networks are the foundation of deep learning.",
			},
		},
		{
			filename: "doc2.md",
			chunks: []string{
				"Database systems are essential for data storage.",
				"Vector databases enable similarity search.",
				"SQLite is a lightweight embedded database.",
			},
		},
		{
			filename: "doc3.md",
			chunks: []string{
				"Go is a statically typed programming language.",
				"Go has excellent concurrency support with goroutines.",
				"The Go standard library is comprehensive and well-designed.",
			},
		},
	}

	// Create dummy embeddings (384 dimensions)
	// In real use, these would come from the embedding model
	embedDim := 384
	rand.Seed(time.Now().UnixNano())

	for _, tc := range testCases {
		embeddings := make([][]float32, len(tc.chunks))
		for i := range tc.chunks {
			// Generate random embeddings for testing
			// In production, these would be generated by the ONNX model
			embedding := make([]float32, embedDim)
			for j := 0; j < embedDim; j++ {
				embedding[j] = rand.Float32()
			}
			// Normalize the vector
			embedding = normalizeVector(embedding)
			embeddings[i] = embedding
		}

		// Insert document
		err := db.InsertDocument(tc.filename, time.Now(), convertToChunkInterfaces(tc.chunks), embeddings)
		if err != nil {
			fmt.Fprintf(os.Stderr, "[ERROR] Failed to insert document %s: %v\n", tc.filename, err)
			continue
		}
		fmt.Fprintf(os.Stderr, "[INFO] Inserted %s with %d chunks\n", tc.filename, len(tc.chunks))
	}

	// Perform vector search
	fmt.Fprintf(os.Stderr, "\n[INFO] Performing vector search...\n")

	// Create a query vector (random for testing)
	queryVector := make([]float32, embedDim)
	for i := 0; i < embedDim; i++ {
		queryVector[i] = rand.Float32()
	}
	queryVector = normalizeVector(queryVector)

	// Search for top 5 results
	topK := 5
	results, err := db.Search(queryVector, topK)
	if err != nil {
		fmt.Fprintf(os.Stderr, "[FATAL] Search failed: %v\n", err)
		os.Exit(1)
	}

	// Display results
	fmt.Fprintf(os.Stderr, "\n=== Search Results (Top %d) ===\n", topK)
	for i, result := range results {
		fmt.Fprintf(os.Stderr, "\nRank %d:\n", i+1)
		fmt.Fprintf(os.Stderr, "  Document: %s\n", result.DocumentName)
		fmt.Fprintf(os.Stderr, "  Position: %d\n", result.Position)
		fmt.Fprintf(os.Stderr, "  Similarity: %.4f\n", result.Similarity)
		fmt.Fprintf(os.Stderr, "  Content: %s\n", truncate(result.ChunkContent, 80))
	}

	// Test with different topK values
	fmt.Fprintf(os.Stderr, "\n[INFO] Testing with topK=3...\n")
	results, err = db.Search(queryVector, 3)
	if err != nil {
		fmt.Fprintf(os.Stderr, "[ERROR] Search with topK=3 failed: %v\n", err)
	} else {
		fmt.Fprintf(os.Stderr, "[INFO] Retrieved %d results (expected 3)\n", len(results))
	}

	// Test edge case: topK larger than available results
	fmt.Fprintf(os.Stderr, "\n[INFO] Testing with topK=100 (more than available)...\n")
	results, err = db.Search(queryVector, 100)
	if err != nil {
		fmt.Fprintf(os.Stderr, "[ERROR] Search with topK=100 failed: %v\n", err)
	} else {
		totalChunks := 0
		for _, tc := range testCases {
			totalChunks += len(tc.chunks)
		}
		fmt.Fprintf(os.Stderr, "[INFO] Retrieved %d results (total chunks: %d)\n", len(results), totalChunks)
	}

	// Performance test
	fmt.Fprintf(os.Stderr, "\n[INFO] Performance test: 100 searches...\n")
	start := time.Now()
	numSearches := 100
	for i := 0; i < numSearches; i++ {
		_, err := db.Search(queryVector, 5)
		if err != nil {
			fmt.Fprintf(os.Stderr, "[ERROR] Search %d failed: %v\n", i, err)
			break
		}
	}
	duration := time.Since(start)
	avgTime := duration / time.Duration(numSearches)
	searchesPerSec := float64(numSearches) / duration.Seconds()
	fmt.Fprintf(os.Stderr, "[INFO] Total time: %v\n", duration)
	fmt.Fprintf(os.Stderr, "[INFO] Average search time: %v\n", avgTime)
	fmt.Fprintf(os.Stderr, "[INFO] Searches per second: %.0f\n", searchesPerSec)

	fmt.Fprintf(os.Stderr, "\n[SUCCESS] All vector search tests passed!\n")
}

// normalizeVector performs L2 normalization on a vector
func normalizeVector(vec []float32) []float32 {
	var sum float32
	for _, v := range vec {
		sum += v * v
	}
	if sum == 0 {
		return vec
	}
	norm := float32(1.0) / sqrt32(sum)
	result := make([]float32, len(vec))
	for i, v := range vec {
		result[i] = v * norm
	}
	return result
}

// sqrt32 computes square root for float32
func sqrt32(x float32) float32 {
	// Simple Newton's method
	if x <= 0 {
		return 0
	}
	z := x
	for i := 0; i < 10; i++ {
		z = (z + x/z) / 2
	}
	return z
}

// truncate truncates a string to maxLen characters
func truncate(s string, maxLen int) string {
	if len(s) <= maxLen {
		return s
	}
	return s[:maxLen-3] + "..."
}

// convertToChunkInterfaces converts string slices to vectordb.ChunkInterface
func convertToChunkInterfaces(chunks []string) []vectordb.ChunkInterface {
	result := make([]vectordb.ChunkInterface, len(chunks))
	for i, content := range chunks {
		result[i] = &testChunk{content: content, position: i}
	}
	return result
}

// testChunk implements the chunk interface
type testChunk struct {
	content  string
	position int
}

func (c *testChunk) GetContent() string { return c.content }
func (c *testChunk) GetPosition() int   { return c.position }
